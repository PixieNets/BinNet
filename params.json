{
  "name": "PixieNet",
  "tagline": "16-623 CMU Course project",
  "body": "####Team Members\r\nEsha Uboweja, Salvador Medina\r\n\r\n## Project Proposal\r\n\r\n### Summary\r\n\r\nWe aim to implement a binary convolutional neural network capable of being executed on an iOS device to run image classification on image frames captured by the device's camera.\r\n\r\n![Is that a bird?!](images/tasks_xkcd_1425.png)\r\nPerforming image detection on a mobile device ([source](http://xkcd.com/1425/))\r\n\r\n### Background\r\n\r\n* **Why is this a mobile device application project?**\r\n\r\nConvolutional neural networks work really well in tasks like object recognition and scene classification, and for building image embeddings (vectorial or feature representations) that can in turn be used in more complex tasks such as scene navigation, obstacle avoidance etc.\r\n\r\nPresently, there are many popular libraries and frameworks for deep learning such as Google's TensorFlow, Facebook's Torch, Caffe, Theano etc. There are iOS versions of some of these frameworks, such as TensorFlow and Torch. We examined an application published in the TensorFlow repository ([Object detection via the camera app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/ios_examples)) wherein a pre-trained GoogleLeNet model (size approx. 50 MB) was able to perform object recognition on a video on our iPad Air 2 at 6.8 FPS. This is a decent speed because the application is able to perform real time object recognition on the iOS device. However, when we tried to change the application code to use a pre-trained VGG-16 Network (trained on 1001 classes of ImageNet dataset) instead, the application crashed due to the huge size of the weights file (approx. 553.5 MB). \r\n\r\n_Simply put, there is a problem of a huge memory footprint of many existing deep networks._\r\n\r\nThe ability of running such networks on mobile devices can help in research projects and applications. For instance, a high performance and accurate object/scene classifier can be used to guide the visually impaired, as it can give a coarse description of their surroundings. Further, a full working CNN on a mobile device will help in reducing the workload on server side computation (as how currently networks run in the cloud) as now the forward pass of a neural net can compute image features on the user's device.\r\n\r\n* **Computational speedups**\r\n\r\nWe aim to implement binary networks as described in [XNOR-Net](https://arxiv.org/abs/1603.05279). The key insight is that binary values occupy less memory than double/single-precision floating point values and hence if we use binary valued parameters and weights for the many layers and binary valued inputs, the memory footprint of the network will decrease. Further, operations like convolution can be implemented using binary operations that are faster than an _O(N^3)_ matrix multiplication. \r\n\r\nThe implementation will therefore tap every possible source of speedup such as using fast matrix operation libraries like Armadillo, Accelerate framework, Eigen and very likely also tap the GPU using Metal in Objective-C. We will present some evidence as to what we actually choose in our final implementation when we present benchmarks for our project (please see the [Goals & Deliverables](.#Goals-&-Deliverables) section).\r\n\r\n### The Challenge\r\n\r\n\r\n### Goals & Deliverables\r\n\r\n\r\n### Schedule",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}